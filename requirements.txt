# The requirements file for the project generated by pip-compile requirements.in
# and the pip freeze command on Marqo 2.13.1.

aiohappyeyeballs==2.4.3
    # via aiohttp
aiohttp==3.10.9
    # via
    #   datasets
    #   fsspec
aiosignal==1.3.1
    # via aiohttp
anyio==3.7.1
    # via
    #   -r requirements.in
    #   starlette
    #   watchfiles
async-timeout==4.0.3
    # via
    #   aiohttp
    #   redis
attrs==24.2.0
    # via
    #   aiohttp
    #   jsonschema
audioread==3.0.1
    # via librosa
av==12.3.0
    # via pytorchvideo
boto3==1.25.4
    # via -r requirements.in
botocore==1.28.4
    # via
    #   -r requirements.in
    #   boto3
    #   s3transfer
cachetools==5.3.1
    # via -r requirements.in
certifi==2019.11.28
    # via
    #   -r requirements.in
    #   requests
cffi==1.17.1
    # via soundfile
charset-normalizer==2.1.1
    # via requests
click==8.1.7
    # via
    #   nltk
    #   uvicorn
clip-marqo==1.0.2
    # via -r requirements.in
coloredlogs==15.0.1
    # via
    #   onnxruntime
    #   optimum
datasets==2.19.1
    # via optimum
decorator==5.1.1
    # via
    #   librosa
    #   validators
dill==0.3.8
    # via
    #   datasets
    #   multiprocess
einops==0.6.1
    # via -r requirements.in
exceptiongroup==1.2.2
    # via anyio
fastapi==0.86.0
    # via
    #   -r requirements.in
    #   fastapi-utils
fastapi-utils==0.2.1
    # via -r requirements.in
ffmpeg-python==0.2.0
    # via -r requirements.in
filelock==3.16.1
    # via
    #   datasets
    #   huggingface-hub
    #   transformers
flatbuffers==23.5.9
    # via
    #   -r requirements.in
    #   onnxruntime
frozenlist==1.4.1
    # via
    #   aiohttp
    #   aiosignal
fsspec==2024.3.1
    # via
    #   datasets
    #   huggingface-hub
ftfy==6.2.3
    # via
    #   clip-marqo
    #   open-clip-torch
future==1.0.0
    # via ffmpeg-python
fvcore==0.1.5.post20221221
    # via pytorchvideo
greenlet==3.1.1
h11==0.14.0
    # via uvicorn
httpcore==0.18.0
    # via httpx
httptools==0.6.1
    # via uvicorn
httpx==0.25.0
   # via -r requirements.in
huggingface-hub==0.25.0
    # via
    #   datasets
    #   open-clip-torch
    #   optimum
    #   sentence-transformers
    #   timm
    #   tokenizers
    #   transformers
humanfriendly==10.0
    # via coloredlogs
idna==2.8
    # via
    #   -r requirements.in
    #   anyio
    #   requests
    #   yarl
importlib_metadata==8.5.0
    # via numba
importlib_resources==6.4.5
    # via jsonschema
iopath==0.1.10
    # via
    #   fvcore
    #   pytorchvideo
Jinja2==3.1.4
    # via -r requirements.in
jmespath==1.0.1
    # via
    #   boto3
    #   botocore
joblib==1.4.2
    # via
    #   librosa
    #   nltk
    #   scikit-learn
jsonschema==4.17.1
    # via -r requirements.in
kazoo==2.10.0
    # via -r requirements.in
lazy_loader==0.4
    # via librosa
librosa==0.10.2.post1
    # via -r requirements.in
llvmlite==0.41.1
    # via numba
MarkupSafe==2.1.5
    # via Jinja2
memory-profiler==0.61.0
    # via -r requirements.in
more-itertools==10.4.0
    # via -r requirements.in
mpmath==1.3.0
    # via sympy
msgpack==1.1.0
    # via librosa
multidict==6.1.0
    # via
    #   aiohttp
    #   yarl
multilingual-clip==1.0.10
    # via -r requirements.in
multiprocess==0.70.16
    # via datasets
networkx==3.1
    # via pytorchvideo
nltk==3.9.1
    # via
    #   -r requirements.in
    #   sentence-transformers
numba==0.58.1
    # via librosa
numpy==1.23.4
    # via
    #   -r requirements.in
    #   datasets
    #   fvcore
    #   librosa
    #   numba
    #   onnx
    #   onnxruntime
    #   opencv-python-headless
    #   optimum
    #   pandas
    #   scikit-learn
    #   scipy
    #   sentence-transformers
    #   soxr
    #   torchvision
    #   transformers
onnx==1.12.0
    # via -r requirements.in
onnxruntime==1.13.1
    # via -r requirements.in
open-clip-torch==2.24.0
    # via -r requirements.in
opencv-python-headless==4.6.0.66
    # via -r requirements.in
optimum==1.20.0
    # via -r requirements.in
packaging==24.1
    # via
    #   datasets
    #   huggingface-hub
    #   lazy-loader
    #   onnxruntime
    #   optimum
    #   pooch
    #   transformers
pandas==1.5.1
    # via
    #   -r requirements.in
    #   datasets
parameterized==0.9.0
    # via pytorchvideo
pillow==10.4.0
    # via
    #   -r requirements.in
    #   fvcore
    #   torchvision
pkgutil_resolve_name==1.3.10
    # via jsonschema
platformdirs==4.3.6
    # via pooch
pooch==1.8.2
    # via librosa
portalocker==2.10.1
    # via iopath
protobuf==3.20.1
    # via
    #   -r requirements.in
    #   onnx
    #   onnxruntime
    #   open-clip-torch
    #   transformers
psutil==5.9.4
    # via -r requirements.in
pyarrow==17.0.0
    # via datasets
pyarrow-hotfix==0.6
    # via datasets
pycparser==2.22
    # via cffi
pycurl==7.45.3
    # via -r requirements.in
pydantic==1.10.11
    # via
    #   fastapi
    #   fastapi-utils
pynvml==11.5.0
    # via -r requirements.in
pyrsistent==0.20.0
    # via jsonschema
python-dateutil==2.9.0.post0
    # via
    #   botocore
    #   pandas
python-dotenv==1.0.1
    # via uvicorn
python-magic==0.4.27
    # via -r requirements.in
pytorchvideo==0.1.5
    # via -r requirements.in
pytz==2024.2
    # via pandas
PyYAML==6.0.2
    # via
    #   datasets
    #   fvcore
    #   huggingface-hub
    #   timm
    #   transformers
    #   uvicorn
    #   yacs
readerwriterlock==1.0.9
    # via -r requirements.in
redis==4.4.2
    # via -r requirements.in
regex==2024.9.11
    # via
    #   clip-marqo
    #   nltk
    #   open-clip-torch
    #   transformers
requests==2.28.1
    # via
    #   -r requirements.in
    #   datasets
    #   huggingface-hub
    #   pooch
    #   torchvision
    #   transformers
s3transfer==0.6.2
    # via boto3
safetensors==0.4.1
    # via
    #   -r requirements.in
    #   timm
    #   transformers
scikit-learn==1.3.2
    # via
    #   librosa
    #   sentence-transformers
scipy==1.10.1
    # via
    #   librosa
    #   scikit-learn
    #   sentence-transformers
semver==3.0.2
    # via -r requirements.in
sentence-transformers==2.2.2
    # via -r requirements.in
sentencepiece==0.2.0
    # via
    #   open-clip-torch
    #   sentence-transformers
    #   transformers
six==1.14.0
    # via
    #   -r requirements.in
    #   python-dateutil
sniffio==1.3.1
    # via anyio
soundfile==0.12.1
    # via
    #   -r requirements.in
    #   librosa
soxr==0.3.7
    # via librosa
SQLAlchemy==1.4.54
    # via fastapi-utils
starlette==0.20.4
    # via fastapi
sympy==1.13.3
    # via
    #   onnxruntime
    #   optimum
tabulate==0.9.0
    # via fvcore
termcolor==2.4.0
    # via fvcore
threadpoolctl==3.5.0
    # via scikit-learn
timm==1.0.8
    # via
    #   -r requirements.in
    #   open-clip-torch
tokenizers==0.19.1
    # via transformers
tqdm==4.66.5
    # via
    #   clip-marqo
    #   datasets
    #   fvcore
    #   huggingface-hub
    #   iopath
    #   nltk
    #   open-clip-torch
    #   sentence-transformers
    #   transformers
transformers==4.41.2
    # via
    #   -r requirements.in
    #   multilingual-clip
    #   optimum
    #   sentence-transformers
typing_extensions==4.5.0
    # via
    #   -r requirements.in
    #   huggingface-hub
    #   iopath
    #   librosa
    #   multidict
    #   onnx
    #   pydantic
    #   starlette
    #   torch
    #   torchvision
    #   uvicorn
urllib3==1.26.16
    # via
    #   -r requirements.in
    #   botocore
    #   requests
uvicorn==0.31.0
    # via -r requirements.in
uvloop==0.20.0
    # via uvicorn
validators==0.20.0
    # via -r requirements.in
watchfiles==0.24.0
    # via uvicorn
wcwidth==0.2.13
    # via ftfy
websockets==13.1
    # via uvicorn
xxhash==3.5.0
    # via datasets
yacs==0.1.8
    # via fvcore
yarl==1.13.1
    # via aiohttp
zipp==3.20.2
    # via
    #   importlib_metadata
    #   importlib_resources

######## Platform Specific Packages ########
# AMD Specific packages
--extra-index-url https://download.pytorch.org/whl/cu113
torch==1.12.1+cu113; platform_machine == "x86_64"
    # via
    #   -r requirements.in
    #   clip-marqo
    #   open-clip-torch
    #   optimum
    #   sentence-transformers
    #   timm
    #   torchaudio
    #   torchvision
torchaudio==0.12.1+cu113; platform_machine == "x86_64"
    # via -r requirements.in
torchvision==0.13.1+cu113; platform_machine == "x86_64"
    # via
    #   -r requirements.in
    #   clip-marqo
    #   open-clip-torch
    #   sentence-transformers
    #   timm
onnxruntime-gpu==1.12.1; platform_machine == "x86_64"
    # via
    #   -r requirements.in
decord==0.6.0; platform_machine == "x86_64"
    # via
    #   -r requirements.in
    # https://github.com/georgia-tech-db/eva-decord is a fork of decord that only works on macos
    # And there isn't any version working for linux/arm64 for now: https://github.com/dmlc/decord/issues/297
    # pip3 --no-cache-dir install --upgrade eva-decord==0.6.1

# ARM Specific packages
torch==1.12.1; platform_machine == "arm64" or platform_machine == "aarch64"
    # via
    #   -r requirements.in
    #   clip-marqo
    #   open-clip-torch
    #   optimum
    #   sentence-transformers
    #   timm
    #   torchaudio
    #   torchvision
torchaudio==0.12.1; platform_machine == "arm64" or platform_machine == "aarch64"
    # via -r requirements.in
torchvision==0.13.1; platform_machine == "arm64" or platform_machine == "aarch64"
    # via
    #   -r requirements.in
    #   clip-marqo
    #   open-clip-torch
    #   sentence-transformers
    #   timm
